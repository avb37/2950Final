{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset of moderate size and complexity.\n",
    "\n",
    "It should be large enough to have interesting complexity, but not so big as to be unwieldy. \n",
    "\n",
    "As a rough guideline, your dataset should be longer than you could print on a single page in standard spreadsheet format, but smaller than 20 MB.\n",
    "\n",
    "You may use existing datasets, combine data from APIs, or create entirely new data through instruments or surveys.\n",
    "\n",
    "The dataset you turn in does not have to be the dataset that you initially collected. For example, you might download 50 MB of raw logs, but use filtering and aggregation to reduce the dataset to 100 kB for your actual analysis. \n",
    "\n",
    "We want you to submit your analysis-ready data, but you should describe your full data-collection protocol and any preprocessing done in the data description section of your final report (see below). All source code use for data collection and preprocessing should also be linked to in the source code section of your final report. \n",
    "\n",
    "\n",
    "If your final, curated dataset is larger than 10MB, share a copy in Cornell Box and include a link to it in your final report.\n",
    "\n",
    "\n",
    "A final report, as a Jupyter notebook with executed cells, containing the following sections: \n",
    "\n",
    "### Introduction.\n",
    "What is the context of the work? What research question are you trying to answer? What are your main findings? Include a brief summary of your results.\n",
    "\n",
    "\n",
    "### Data description. \n",
    "This should be inspired by the format presented in Gebru et al, 2018. Answer any relevant questions from sections 3.1-3.5 of the Gebru et al article, especially the following questions:\n",
    "- What are the observations (rows) and the attributes (columns)?\n",
    "- Why was this dataset created?\n",
    "- Who funded the creation of the dataset?\n",
    "- What processes might have influenced what data was observed and recorded and what was not?\n",
    "- What preprocessing was done, and how did the data come to be in the form that you are using?\n",
    "- If people are involved, were they aware of the data collection and if so, what purpose did they expect the data to be used for?\n",
    "- Where can your raw source data be found, if applicable? Provide a link to the raw data (hosted in a Cornell Google Drive or Cornell Box). \n",
    "\n",
    "### Preregistration statement. \n",
    "List the two analyses you promised to perform in this final report from your Phase III submission.\n",
    "\n",
    "### Data analysis.\n",
    "Use summary functions like mean and standard deviation along with visual displays like scatterplots and histograms to describe data.\n",
    "\n",
    "Provide at least one model showing patterns or relationships between variables that addresses your research question. This could be a regression or clustering, or something else that measures some property of the dataset.\n",
    "\n",
    "### Evaluation of significance. \n",
    "Use hypothesis tests, simulation, randomization, or any other techniques we have learned to compare the patterns you observe in the dataset to simple randomness. \n",
    "\n",
    "### Interpretation and conclusions. \n",
    "What did you find over the course of your data analysis, and how confident are you in these conclusions? Detail your results more so than in the introduction, now that the reader is familiar with your methods and analysis. \n",
    "\n",
    "Interpret these results in the wider context of the real-life application from where your data hails.\n",
    "\n",
    "### Limitations. \n",
    "What are the limitations of your study? What are the biases in your data or assumptions of your analyses that specifically affect the conclusions you’re able to draw?\n",
    "\n",
    "### Source code.\n",
    "Provide a link to your Github repository (or other file hosting site) that has all of your project code (if applicable). For example, you might include web scraping code or data filtering and aggregation code.\n",
    "\n",
    "### Acknowledgments. \n",
    "Recognize any people or online resources that you found helpful. These can be tutorials, software packages, Stack Overflow questions, peers, and data sources. Showing gratitude is a great way to feel happier! But it also has the nice side-effect of reassuring us that you're not passing off someone else's work as your own. Crossover with other courses is permitted and encouraged, but it must be clearly stated, and it must be obvious what parts were and were not done for 2950. Copying without attribution robs you of the chance to learn, and wastes our time investigating.\n",
    "\n",
    "### Appendix:\n",
    "Data cleaning description. Submit an updated version of your data cleaning description from phase II that describes all data cleaning steps performed on your raw data to turn it into the analysis-read dataset submitted with your final project. The data cleaning description should be a separate Jupyter notebook with executed cells, and it should output the dataset you submit as part of your project (e.g. written as a .csv file).\n",
    "\n",
    "### (Optional) Other appendices. \n",
    "You will almost certainly feel that you have done a lot of work that didn't end up in the final report. We want you to edit and focus, but we also want to make sure that there's a place for work that didn't work out or that didn't fit in the final presentation. \n",
    "\n",
    "You may include any analyses you tried but were tangential to the final direction of your main report. Graders may briefly look at these appendices, but they also may not. You want to make your final report interesting enough that the graders don’t feel the need to look at other things you tried. “Interesting” doesn’t necessarily mean that the results in your final report were all statistically significant; it could be that your results were not significant but you were able to interpret them in an interesting and informed way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
